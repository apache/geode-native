#! Licensed to the Apache Software Foundation (ASF) under one or more
#! contributor license agreements.  See the NOTICE file distributed with
#! this work for additional information regarding copyright ownership.
#! The ASF licenses this file to You under the Apache License, Version 2.0
#! (the "License"); you may not use this file except in compliance with
#! the License.  You may obtain a copy of the License at
#!
#!      http://www.apache.org/licenses/LICENSE-2.0
#!
#! Unless required by applicable law or agreed to in writing, software
#! distributed under the License is distributed on an "AS IS" BASIS,
#! WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#! See the License for the specific language governing permissions and
#! limitations under the License.

#@ load("@ytt:data", "data")

#@ load("templates.lib.txt",
#@      "remote_functions",
#@      "instance_variables",
#@      "google_variables",
#@      "run_cpp_unit_tests",
#@      "run_cpp_integration_tests",
#@      "run_cpp_legacy_integration_tests",
#@      "run_net_unit_tests",
#@      "run_net_integration_tests",
#@      "run_net_legacy_integration_tests")

#@ def resource(name, type, source=None, icon=None):
#@ return {
#@   "name": name,
#@   "type": type,
#@   "source": source,
#@   "icon": icon
#@ }
#@ end

#@ def registry_image_resource(name, repository, tag="latest", username=None, password=None, mirror="mirror.gcr.io"):
#@ return resource(name, "registry-image", {
#@   "repository": repository,
#@   "tag": tag,
#@   "username": username,
#@   "password": password,
#@   "registry_mirror": {
#@     "host": mirror
#@   }
#@ }, "docker")
#@ end

#@ def gcr_image_resource(name, repository, tag="latest"):
#@ return registry_image_resource(name, "gcr.io/" + repository, tag, "_json_key", "((gcr-json-key))", None)
#@ end

#@ def docker_image_resource(name, repository, tag="latest", username=None, password=None):
#@ return resource(name, "docker-image", {
#@   "repository": repository,
#@   "tag": tag,
#@   "username": username,
#@   "password": password,
#@  }, "docker")
#@ end

#@ def project_gcr_image_resource(name, repository, tag="latest"):
#@ return docker_image_resource(name, "gcr.io/" + data.values.google.project + "/" + repository, tag, "_json_key", "((gcr-json-key))")
#@ end

#@ def git_resource(name, uri, branch, paths=[], ignore_paths=[], depth=1):
#@ return resource(name, "git", {
#@   "branch": branch,
#@   "depth": depth,
#@   "paths": paths,
#@   "ignore_paths": ignore_paths,
#@   "uri": uri
#@  }, "github")
#@ end

#@ def hyphenated(value):
#! TODO [a-z0-9-]
#@ return value.lower().replace(".", "-").replace("/", "-")
#@ end

#@ def image_family_name(family):
#@ return (data.values.pipeline.name + "-" + family)[0:62]
#@ end

#@ def gci_resource_name(family):
#@ return family + "-gci"
#@ end

#@ def gci_resource(family, project=data.values.google.project):
#@ return resource(gci_resource_name(family), "gci", {
#@   "key": "((gcr-json-key))",
#@   "family_project": project,
#@   "family": family,
#@  }, "google-cloud")
#@ end

#@ def create_instance(build, config):
task: create
image: gcloud-image
config:
  platform: linux
  inputs:
    - name: #@ gci_resource_name(image_family_name(build.image_family))
      path: image
  outputs:
    - name: instance
  params:
    LABEL_PIPELINE_NAME: #@ gci_label_value(data.values.pipeline.name)
    LABEL_BUILD_CONFIG: #@ config.name
  run:
    path: bash
    args:
      - -c
      #@yaml/text-templated-strings
      - |
        set -ueo pipefail
        (@= google_variables() @)
        (@= instance_variables() @)

        ssh_key_file=${INSTANCE_DIR}/identity
        ssh_pubkey_file=${ssh_key_file}.pub
        ssh-keygen -m pem  -t rsa -f ${ssh_key_file} -C "${INSTANCE_USER}" -N '' <<< y
        ssh_pubkey=$(cat ${ssh_pubkey_file})

        ssh_keys_file=${INSTANCE_DIR}/ssh_keys_file
        echo "${INSTANCE_USER}:${ssh_pubkey}" > ${ssh_keys_file}

        instance_name=build-$(cat /proc/sys/kernel/random/uuid)
        image_name=$(cat image/name)
        time_to_live=$(( $(date +%s) + ( 4 * 60 * 60 ) ))

        instance_file=${INSTANCE_DIR}/instance.sh
        gcloud compute instances create ${instance_name} \
            --format='config[export](name,networkInterfaces[0].accessConfigs[0].natIP)' \
            --project=${GOOGLE_PROJECT} \
            --zone=${GOOGLE_ZONE} \
            --subnet=default \
            --machine-type=e2-standard-16 \
            --boot-disk-size=200GB \
            --boot-disk-type=pd-standard \
            --boot-disk-device-name=${instance_name} \
            --image-project=${GOOGLE_PROJECT} \
            --image=${image_name} \
            --metadata-from-file ssh-keys=${ssh_keys_file} \
            --labels=time-to-live=${time_to_live},pipeline-name=${LABEL_PIPELINE_NAME},build-config=${LABEL_BUILD_CONFIG} \
            > ${instance_file}

        (@= remote_functions() @)
        SSH_OPTIONS="${SSH_OPTIONS} -o ConnectTimeout=10"

        echo "Waiting for ssh on ${instance_name} to be ready."
        console_file=$(mktemp)
        console_next=0
        while ! remote_shell echo ready 2>/dev/null ; do
          gcloud compute instances get-serial-port-output ${instance_name} \
              --start ${console_next} \
              --project=${GOOGLE_PROJECT} \
              --zone=${GOOGLE_ZONE} \
              --format='value[separator="
        "](next,contents)' \
              > ${console_file}

          tmp_next=$(head -n 1 ${console_file})
          if (( tmp_next != console_next )); then
            console_next=${tmp_next}
            sed '1d;s/\x1b\[[0-9;]*[JH]//g' ${console_file}
          fi
        done
#@ end

#@ load("@ytt:template", "template")

#@ def build_task(config, params={}):
task: build
image: task-image
config:
  platform: linux
  inputs:
    - name: instance
    - name: source
  outputs:
    - name: package
  params:
    _: #@ template.replace(params)
    _: #@ template.replace({"CMAKE_CONFIG": config})
  run:
    path: bash
    args:
      - -c
      #@yaml/text-templated-strings
      - |
        set -ueo pipefail

        (@= remote_functions() @)

        pushd source
        git_url=$(git remote get-url origin)
        git_rev=$(git rev-parse HEAD)
        popd

        remote_shell git clone ${git_url} source
        remote_shell cmake -E chdir source git checkout ${git_rev}
        remote_shell cmake -E make_directory build
        remote_shell cmake -E chdir build cmake ../source ${CMAKE_CONFIGURE_FLAGS} -DCMAKE_config=${CMAKE_CONFIG}
        remote_shell cmake --build build --config ${CMAKE_CONFIG} -- ${CMAKE_BUILD_FLAGS}
        remote_shell cmake --build build --config ${CMAKE_CONFIG} --target docs -- ${CMAKE_BUILD_FLAGS}
        remote_shell cmake -E chdir build cpack -C ${CMAKE_CONFIG} -G "${CPACK_GENERATORS}" | tee cpack.out

        packages=$(awk '/^CPack: - package: / {print $4}' cpack.out)
        for package in ${packages}; do
          remote_copy ${package} package/
        done
        checksums=$(awk '/^CPack: - checksum file: / {print $5}' cpack.out)
        for checksum in ${checksums}; do
          remote_copy ${checksum} package/
        done
#@ end

#@ def remote_task(name, config, commands, timeout, params={}, attempts=1):
task: #@ name
timeout: #@ timeout
image: task-image
attempts: #@ attempts
config:
  platform: linux
  inputs:
    - name: instance
  outputs:
  params:
    _: #@ template.replace(params)
    _: #@ template.replace({"CMAKE_CONFIG": config})
  run:
    path: bash
    args:
      - -c
      #@yaml/text-templated-strings
      - |
        set -ueo pipefail
        (@= remote_functions() @)
        (@= commands @)
#@ end

#@ def packer_build_task(build):
#@ end


#@ def cpp_unit_test_task(build, config):
#@ return remote_task("cpp-unit-tests", config.config, run_cpp_unit_tests(), "5m", build.params)
#@ end

#@ def cpp_integration_test_task(build, config):
#@ return remote_task("cpp-integration-tests", config.config, run_cpp_integration_tests(), "30m", build.params, 5)
#@ end

#@ def cpp_legacy_integration_test_task(build, config):
#@ return remote_task("cpp-legacy-integration-tests", config.config, run_cpp_legacy_integration_tests(), "1h", build.params, 5)
#@ end

#@ def net_unit_test_task(build, config):
#@ return remote_task("net-unit-tests", config.config, run_net_unit_tests(), "5m", build.params)
#@ end

#@ def net_integration_test_task(build, config):
#@ return remote_task("net-integration-tests", config.config, run_net_integration_tests(), "30m", build.params)
#@ end

#@ def net_legacy_integration_test_task(build, config):
#@ return remote_task("net-legacy-integration-tests", config.config, run_net_legacy_integration_tests(), "1h", build.params, 5)
#@ end

#@ def download_build_task():
task: download-build
image: task-image
config:
  platform: linux
  inputs:
    - name: instance
  outputs:
    - name: build
  params:
  run:
    path: bash
    args:
      - -c
      #@yaml/text-templated-strings
      - |
        set -ueo pipefail
        (@= remote_functions() @)

        remote_copy_recursive build .
#@ end

#@ def delete_instance():
task: delete
image: gcloud-image
config:
  platform: linux
  inputs:
    - name: instance
  params:
  run:
    path: bash
    args:
      - -c
      #@yaml/text-templated-strings
      - |
        set -ueo pipefail
        (@= google_variables() @)
        (@= remote_functions() @)

        instance_name=$(source ${instance_file} && echo -n ${name})

        gcloud compute instances delete ${instance_name} \
            --project=${GOOGLE_PROJECT} \
            --zone=${GOOGLE_ZONE} \
            --delete-disks=all \
            --quiet
#@ end

#@ def build_job_name(build, config):
#@ return "build-" + build.name + "-" + config.name
#@ end

#@ def build_job(build, config):
name: #@ build_job_name(build, config)
plan:
  - in_parallel:
      fail_fast: true
      steps:
        - get: source
          trigger: true
        - do:
            - in_parallel:
                fail_fast: true
                steps:
                  - get: gcloud-image
                  - get: task-image
                  - get: #@ gci_resource_name(image_family_name(build.image_family))
                    trigger: true
            - #@ create_instance(build, config)
  - do:
      - #@ build_task(config.config, build.params)
      - #@ cpp_unit_test_task(build, config)
      - #@ cpp_integration_test_task(build, config)
      - #@ cpp_legacy_integration_test_task(build, config)
      #@ if build.with_dot_net:
      - #@ net_unit_test_task(build, config)
      - #@ net_integration_test_task(build, config)
      - #@ net_legacy_integration_test_task(build, config)
      #@ end
on_failure: #@ download_build_task()
ensure: #@ delete_instance()
#@ end

#@ def gci_label_value(value):
#! TODO [a-z0-9_-]
#@ return hyphenated(value[0:62])
#@ end

#@ def packer_job_name(build):
#@ return "packer-" + build.image_family
#@ end

#@ def packer_job(build):
name: #@ packer_job_name(build)
plan:
  - in_parallel:
      fail_fast: true
      steps:
        - get: packer-image
        - get: #@ gci_resource_name(build.source_image_family)
          trigger: true
        - get: packer-source
          trigger: false
  - task: build
    image: packer-image
    config:
      platform: linux
      inputs:
        - name: packer-source
          path: source
      params:
      run:
        path: bash
        args:
          - -c
          #@yaml/text-templated-strings
          - |
            set -ueo pipefail
            cd source/packer
            packer build -only=googlecompute \
                -var-file=default.json \
                -var pipeline=(@= gci_label_value(data.values.pipeline.name) @) \
                -var repository=(@= gci_label_value(data.values.repository.url) @) \
                -var branch=(@= gci_label_value(data.values.repository.branch) @) \
                -var image_name_prefix=(@= image_family_name(build.image_family)[0:51] @) \
                -var image_family=(@= image_family_name(build.image_family) @) \
                (@= build.image_family @).json

#@ end

#@ def update_pipeline_job_name():
#@ return "update-pipeline"
#@ end

#@ def update_pipeline_job():
name: #@ update_pipeline_job_name()
serial: true
plan:
  - in_parallel:
      fail_fast: true
      steps:
        - get: ytt-image
        - get: ci-source
          trigger: true
  - task: ytt
    image: ytt-image
    config:
      platform: linux
      inputs:
        - name: ci-source
          path: source
      outputs:
        - name: pipeline
      params:
      run:
        path: /usr/bin/ytt
        args:
          - --file
          - source/ci/.
          - --data-value
          - #@ "pipeline.name=" + data.values.pipeline.name
          - --data-value
          - #@ "repository.url=" + data.values.repository.url
          - --data-value
          - #@ "repository.branch=" + data.values.repository.branch
          - --data-value
          - #@ "google.project=" + data.values.google.project
          - --data-value
          - #@ "google.zone=" + data.values.google.zone
          - --output-files
          - pipeline/
  - set_pipeline: self
    file: pipeline/pipeline.yml
#@ end

#@ def docker_job_name(name):
#@ return "docker-" + name
#@ end

#@ def docker_job(name, source, path):
name: #@ docker_job_name(name)
plan:
  - get: #@ source
    trigger: true
  - put: #@ name
    params:
      build: #@ source + "/" + path
      cache: true
#@ end
